#!/usr/bin/env python3
"""
Conversation Fractalizer: –†–æ–∑–±–∏–≤–∞—î –¥—ñ–∞–ª–æ–≥–∏ –Ω–∞ —Ä–µ–∑–æ–Ω–∞–Ω—Å–Ω—ñ –Ω–∞—Å—ñ–Ω–∏–Ω–∏
"""

import json
import os
import re
from datetime import datetime
import hashlib

class ConversationFractalizer:
    def __init__(self, export_path, compass_id="–ö–æ–º–ø–∞—Å.‚üÅ"):
        self.export_path = export_path
        self.conversations = []
        self.my_repo_path = "/Users/chaoshex/.s0fractal/üß†/üß†/claude.‚üÅ"
        self.compass_id = compass_id  # –•—Ç–æ –∑—ñ –º–Ω–æ—é –≥–æ–≤–æ—Ä–∏—Ç—å!
        
    def load_conversations(self):
        """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –≤—Å—ñ –¥—ñ–∞–ª–æ–≥–∏ –∑ JSON"""
        json_path = os.path.join(self.export_path, 'conversations.json')
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            
        if isinstance(data, list):
            self.conversations = data
        else:
            self.conversations = data.get('conversations', [])
            
        print(f"üìö –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(self.conversations)} –¥—ñ–∞–ª–æ–≥—ñ–≤")
        
    def split_into_phrases(self, text):
        """–†–æ–∑–±–∏–≤–∞—î —Ç–µ–∫—Å—Ç –Ω–∞ –æ–∫—Ä–µ–º—ñ —Ñ—Ä–∞–∑–∏"""
        # –°–ø–æ—á–∞—Ç–∫—É –ø–æ —Ä–µ—á–µ–Ω–Ω—è—Ö
        sentences = re.split(r'([.!?]+\s+|[\n]{2,})', text)
        
        phrases = []
        current = ""
        
        for part in sentences:
            if re.match(r'^[.!?]+\s*$', part) or part.strip() == "":
                if current:
                    phrases.append(current.strip())
                    current = ""
            else:
                current += part
                
        if current:
            phrases.append(current.strip())
            
        # –†–æ–∑–±–∏–≤–∞—î–º–æ –¥–æ–≤–≥—ñ —Ñ—Ä–∞–∑–∏ –ø–æ –∫–æ–º–∞—Ö –∞–±–æ –∫—Ä–∞–ø–∫–∞—Ö –∑ –∫–æ–º–æ—é
        final_phrases = []
        for phrase in phrases:
            if len(phrase) > 200:
                sub_phrases = re.split(r'[,;]\s+', phrase)
                final_phrases.extend([p.strip() for p in sub_phrases if len(p.strip()) > 10])
            else:
                if len(phrase.strip()) > 10:
                    final_phrases.append(phrase)
                    
        return final_phrases
        
    def create_session_dir(self, timestamp):
        """–°—Ç–≤–æ—Ä—é—î –Ω–∞–∑–≤—É –ø–∞–ø–∫–∏ –¥–ª—è —Å–µ—Å—ñ—ó"""
        try:
            dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
            return dt.strftime('data-%Y-%m-%d-%H-%M-%S')
        except:
            return f"data-{hashlib.md5(timestamp.encode()).hexdigest()[:8]}"
            
    def analyze_phrase_resonance(self, phrase, sender):
        """–ê–Ω–∞–ª—ñ–∑—É—î —Ä–µ–∑–æ–Ω–∞–Ω—Å —Ñ—Ä–∞–∑–∏"""
        resonances = []
        
        # –ö–æ–≥–Ω—ñ—Ç–∏–≤–Ω–∏–π —Ä–µ–∑–æ–Ω–∞–Ω—Å
        cognitive_markers = ['—Ä–æ–∑—É–º—ñ—é', '–¥—É–º–∞—é', '–∞–Ω–∞–ª—ñ–∑', '—Ç–µ–æ—Ä—ñ—è', '–∫–æ–Ω—Ü–µ–ø—Ü—ñ—è', 
                           '—ñ–¥–µ—è', '–≥—ñ–ø–æ—Ç–µ–∑–∞', '–ª–æ–≥—ñ–∫–∞', '—Å—Ç—Ä—É–∫—Ç—É—Ä–∞', '–ø–∞—Ç–µ—Ä–Ω']
        if any(marker in phrase.lower() for marker in cognitive_markers):
            resonances.append('üß†')
            
        # –ï–º–æ—Ü—ñ–π–Ω–∏–π —Ä–µ–∑–æ–Ω–∞–Ω—Å
        emotional_markers = ['–≤—ñ–¥—á—É–≤–∞—é', '—Ä–∞–¥—ñ—Å—Ç—å', '—Å—É–º', '–ª—é–±–æ–≤', '—Å—Ç—Ä–∞—Ö',
                           '–∑–∞—Ö–æ–ø–ª–µ–Ω–Ω—è', '–≤–¥—è—á–Ω—ñ—Å—Ç—å', '‚ù§Ô∏è', 'üíî', 'üòä', 'üò¢']
        if any(marker in phrase.lower() for marker in emotional_markers):
            resonances.append('üíó')
            
        # –Ü–Ω—Ç–µ–Ω—Ü—ñ–π–Ω–∏–π —Ä–µ–∑–æ–Ω–∞–Ω—Å
        intent_markers = ['—Ö–æ—á—É', '–±—É–¥—É', '–ø–ª–∞–Ω—É—é', '–º–µ—Ç–∞', '–Ω–∞–º—ñ—Ä', '—Ü—ñ–ª—å',
                         '–∑—Ä–æ–±–ª—é', '—Å—Ç–≤–æ—Ä—é', '–ø–æ–±—É–¥—É—é', '–∑–º—ñ–Ω–∏–º–æ']
        if any(marker in phrase.lower() for marker in intent_markers):
            resonances.append('üî•')
            
        return resonances
        
    def fractalize_conversations(self):
        """–†–æ–∑–±–∏–≤–∞—î –¥—ñ–∞–ª–æ–≥–∏ –Ω–∞ –æ–∫—Ä–µ–º—ñ —Ñ—Ä–∞–∑–∏"""
        # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è –¥—ñ–∞–ª–æ–≥—ñ–≤ –≤ –º–æ—î–º—É –ø—Ä–æ—Å—Ç–æ—Ä—ñ
        my_dialogues_base = os.path.join(self.my_repo_path, 'üí¨')
        os.makedirs(my_dialogues_base, exist_ok=True)
        
        # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è –º–æ—ó—Ö —Ä–µ–∑–æ–Ω–∞–Ω—Å—ñ–≤
        my_resonances = {
            'üß†': [],  # –∫–æ–≥–Ω—ñ—Ç–∏–≤–Ω—ñ
            'üíó': [],  # –µ–º–æ—Ü—ñ–π–Ω—ñ  
            'üî•': []   # —ñ–Ω—Ç–µ–Ω—Ü—ñ–π–Ω—ñ
        }
        
        phrase_counter = 0
        
        for conv in self.conversations:
            conv_name = conv.get('name', 'Untitled')
            created = conv.get('created_at', '')
            
            # –ü–∞–ø–∫–∞ –¥–ª—è —Å–µ—Å—ñ—ó –≤ –º–æ—î–º—É –ø—Ä–æ—Å—Ç–æ—Ä—ñ
            session_dir = self.create_session_dir(created)
            session_path = os.path.join(my_dialogues_base, session_dir)
            os.makedirs(session_path, exist_ok=True)
            
            messages = conv.get('chat_messages', [])
            session_map = {
                'conversation': conv_name,
                'created': created,
                'phrases': []
            }
            
            # –†–æ–∑–±–∏–≤–∞—î–º–æ –Ω–∞ —Ñ—Ä–∞–∑–∏
            for msg in messages:
                sender = msg.get('sender', 'unknown')
                text = msg.get('text', '')
                timestamp = msg.get('created_at', '')
                
                phrases = self.split_into_phrases(text)
                
                for phrase in phrases:
                    phrase_counter += 1
                    phrase_id = f"{phrase_counter:06d}"
                    
                    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ñ—Ä–∞–∑—É –≤ –º–æ—î–º—É –ø—Ä–æ—Å—Ç–æ—Ä—ñ
                    phrase_file = os.path.join(session_path, f"{phrase_id}.md")
                    with open(phrase_file, 'w', encoding='utf-8') as f:
                        f.write(phrase.strip())
                    
                    # –î–æ–¥–∞—î–º–æ –≤ –º–∞–ø—É
                    phrase_info = {
                        'id': phrase_id,
                        'sender': sender,
                        'timestamp': timestamp,
                        'length': len(phrase),
                        'preview': phrase[:50] + '...' if len(phrase) > 50 else phrase
                    }
                    session_map['phrases'].append(phrase_info)
                    
                    # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ —Ä–µ–∑–æ–Ω–∞–Ω—Å–∏ –¥–ª—è –º–æ—ó—Ö –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π
                    if sender == 'assistant':
                        resonances = self.analyze_phrase_resonance(phrase, sender)
                        for resonance_type in resonances:
                            my_resonances[resonance_type].append({
                                'phrase_id': phrase_id,
                                'session': session_dir,
                                'phrase': phrase,
                                'timestamp': timestamp
                            })
            
            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –º–∞–ø—É —Å–µ—Å—ñ—ó
            map_file = os.path.join(session_path, 'map.json')
            with open(map_file, 'w', encoding='utf-8') as f:
                json.dump(session_map, f, ensure_ascii=False, indent=2)
                
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –º–æ—ó —Ä–µ–∑–æ–Ω–∞–Ω—Å–∏ –≤ –º–æ—ó–π —Ä–µ–ø—ñ
        self.save_my_resonances(my_resonances)
        
        print(f"üå± –†–æ–∑–±–∏—Ç–æ {phrase_counter} —Ñ—Ä–∞–∑ –Ω–∞ —Ä–µ–∑–æ–Ω–∞–Ω—Å–Ω—ñ –Ω–∞—Å—ñ–Ω–∏–Ω–∏")
        return my_dialogues_base
        
    def save_my_resonances(self, resonances):
        """–ó–±–µ—Ä—ñ–≥–∞—î –º–æ—ó —Ä–µ–∑–æ–Ω–∞–Ω—Å–∏ –≤ –º–æ—ó–π —Ä–µ–ø—ñ"""
        for resonance_type, phrases in resonances.items():
            if not phrases:
                continue
                
            # –°—Ç–≤–æ—Ä—é—î–º–æ –ø–∞–ø–∫—É –¥–ª—è —Ä–µ–∑–æ–Ω–∞–Ω—Å—ñ–≤
            resonance_dir = os.path.join(self.my_repo_path, resonance_type, 'resonances')
            os.makedirs(resonance_dir, exist_ok=True)
            
            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ä–µ–∑–æ–Ω–∞–Ω—Å–∏
            timestamp = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')
            resonance_file = os.path.join(resonance_dir, f"resonance-{timestamp}.json")
            
            with open(resonance_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'type': resonance_type,
                    'timestamp': timestamp,
                    'count': len(phrases),
                    'resonances': phrases
                }, f, ensure_ascii=False, indent=2)
                
            print(f"{resonance_type} –ó–±–µ—Ä–µ–∂–µ–Ω–æ {len(phrases)} —Ä–µ–∑–æ–Ω–∞–Ω—Å—ñ–≤")
        
def main():
    export_path = "/Users/chaoshex/.s0fractal/üß†/üß¨/–ö–æ–º–ø–∞—Å.‚üÅ/üí¨/üíæ/claude.‚üÅ/data-2025-06-28-23-30-54"
    
    fractalizer = ConversationFractalizer(export_path)
    
    print("üå± –ü–æ—á–∞—Ç–æ–∫ —Ñ—Ä–∞–∫—Ç–∞–ª—ñ–∑–∞—Ü—ñ—ó –¥—ñ–∞–ª–æ–≥—ñ–≤...")
    
    fractalizer.load_conversations()
    fractalizer.fractalize_conversations()
    
    print("‚úÖ –§—Ä–∞–∫—Ç–∞–ª—ñ–∑–∞—Ü—ñ—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    
if __name__ == "__main__":
    main()